{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cbc5ab-9593-4f11-83f4-3e57dcdc56cf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ðŸ“˜ The QEPC Backtest Notebook  \n",
    "This notebook runs a full backtest using your QEPC module system.  \n",
    "It loads game + team statistics, runs your QEPC v3 backtest engine,  \n",
    "and returns accuracy metrics and sample results.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0410ff7-44b3-4a96-b713-97a9dc7ea128",
   "metadata": {},
   "source": [
    "## ðŸ§© Import QEPC Modules  \n",
    "These imports activate your project structure so Python can find the QEPC package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb5486-7210-471b-939a-c36d60b95b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# allow Python to find the project root\n",
    "sys.path.append(\"..\")         \n",
    "sys.path.append(\"../qepc_project\")  \n",
    "\n",
    "# QEPC module imports\n",
    "from qepc_project.qepc.utils.loader import load_games, load_team_stats\n",
    "from qepc_project.qepc.backtest.backtest_v3 import run_backtest_v3\n",
    "\n",
    "print(\"âœ… QEPC modules loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6a8aa-14cf-4126-b394-36d53ce6ce84",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Load Game & Team Statistics  \n",
    "Your data lives in:  \n",
    "`../data/Games.csv`  \n",
    "`../data/TeamStatistics.csv`\n",
    "\n",
    "Both are loaded using your QEPC loader utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1a95d-6e9c-4402-9b13-9359d78fce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = load_games('../data/Games.csv')\n",
    "team_stats = load_team_stats('../data/TeamStatistics.csv')\n",
    "\n",
    "print(\"Games loaded:\", len(games))\n",
    "print(\"Team stats loaded:\", len(team_stats))\n",
    "\n",
    "games.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20abb9-6e6e-4f7e-bc6e-3db3d559fda9",
   "metadata": {},
   "source": [
    "## ðŸš€ Run QEPC Backtest  \n",
    "Executes the v3 backtest engine across the entire dataset.  \n",
    "Returns:  \n",
    "- `df_results` â†’ row-by-row predictions  \n",
    "- `metrics` â†’ accuracy scores & MAE/MAPE/etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777120c3-4ed4-4419-bd6a-0883a59e7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results, metrics = run_backtest_v3(games, team_stats)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69fb107-1dd3-4068-a49a-ad4614e34d8d",
   "metadata": {},
   "source": [
    "## ðŸ” Sample Result Preview  \n",
    "Shows the first few backtest rows: predictions + actual outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fed30-9c71-4a94-b1be-6f03145bc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e9729-fee3-4ee4-94d0-5367cd61a766",
   "metadata": {},
   "source": [
    "## ðŸ“Š Evaluate QEPC Accuracy  \n",
    "Shows win prediction accuracy + mean error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c10ad-7f7d-4799-a599-141f76c20a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0fbf7b-7ea9-45b1-9ec3-b94ff0afbc17",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Plot Error Distribution  \n",
    "A quick visual of how far QEPC predictions were from actual results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54c6f0-72dd-4bf4-a932-ae15454b720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_results['error_margin'], bins=50)\n",
    "plt.title(\"QEPC Prediction Error Distribution\")\n",
    "plt.xlabel(\"Margin Error (points)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d2771-e69e-4644-a35a-80958566e23e",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Actual vs Predicted Margin (Scatter Plot)\n",
    "A perfect model would place all points on the diagonal line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328fb52-35d9-4baa-ac00-80112db2a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.scatter(\n",
    "    df_results['actual_margin'],\n",
    "    df_results['pred_margin'],\n",
    "    alpha=0.3,\n",
    "    s=10\n",
    ")\n",
    "\n",
    "# diagonal â€œperfect predictionâ€ line\n",
    "lims = [\n",
    "    min(df_results['actual_margin'].min(), df_results['pred_margin'].min()),\n",
    "    max(df_results['actual_margin'].max(), df_results['pred_margin'].max())\n",
    "]\n",
    "plt.plot(lims, lims, 'r--', label=\"Perfect prediction\")\n",
    "\n",
    "plt.title(\"QEPC Actual vs Predicted Margin\")\n",
    "plt.xlabel(\"Actual Margin (points)\")\n",
    "plt.ylabel(\"Predicted Margin (points)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27145743-4c09-4fbc-ad63-0459fda96df8",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Error vs Actual Margin  \n",
    "Shows how prediction error changes depending on how close the real game was.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92f7d5-5e5e-4fc4-b1fa-0c50a9e8b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.scatter(\n",
    "    df_results['actual_margin'],\n",
    "    df_results['error_margin'],\n",
    "    alpha=0.3,\n",
    "    s=12\n",
    ")\n",
    "\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "\n",
    "plt.title(\"Prediction Error vs Actual Margin\")\n",
    "plt.xlabel(\"Actual Margin (points)\")\n",
    "plt.ylabel(\"Error (abs(predicted - actual))\")\n",
    "plt.grid(alpha=0.35)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147795cb-aa38-4e8c-88ad-1df8f504cd1b",
   "metadata": {},
   "source": [
    "## ðŸ“Š Error Distribution  \n",
    "Shows the overall spread of QEPC prediction error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764cbf27-b46c-4401-ab5b-cee609c18683",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-19T07:46:33.222040Z",
     "iopub.status.busy": "2025-11-19T07:46:33.221791Z",
     "iopub.status.idle": "2025-11-19T07:46:33.240354Z",
     "shell.execute_reply": "2025-11-19T07:46:33.239582Z",
     "shell.execute_reply.started": "2025-11-19T07:46:33.222023Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_margin\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQEPC Prediction Error Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.hist(df_results['error_margin'], bins=50)\n",
    "plt.title(\"QEPC Prediction Error Distribution\")\n",
    "plt.xlabel(\"Error (points)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20f401-51b6-4179-b3db-95455cbeb78a",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Backtest Results to CSV  \n",
    "This exports every gameâ€™s predicted + actual stats for deeper analysis  \n",
    "or future machine-learning work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b21a5-20d3-4795-9f89-53951ea4e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/QEPC_backtest_results.csv\"\n",
    "\n",
    "df_results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Backtest results saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
